{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Historical data of instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the historical data of instruments that include: \n",
    "\n",
    "- Date\n",
    "- Open\n",
    "- High\n",
    "- Low\n",
    "- Close\n",
    "- Volume\n",
    "- Change_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of symbols or columns through which we can search are:\n",
    "\n",
    "- For stocks: `symbol` column\n",
    "- For funds: `symbol` column\n",
    "- For etfs: `symbol` column\n",
    "- For indices: `symbol` column\n",
    "- For forex currency pairs: `name` column\n",
    "- For bonds: `name` column\n",
    "- For commodities: `name` column\n",
    "- For certificates: `symbol` column\n",
    "- For cryptos: `symbol` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and install the dependencies only once.\n",
    "# ! pip install requests\n",
    "# ! pip install cfscrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers Functions defined, that will be needed for the main execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# import cfscrape\n",
    "\n",
    "# scraper = cfscrape.create_scraper()\n",
    "\n",
    "## Extract the json formatted data from the investing xhr request.\n",
    "def _get_json_(url:str, headers={}, params={}):\n",
    "    print(\"Fetching {}..\".format(url))\n",
    "    response = requests.get(\n",
    "        url=url,\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        json_response = json.loads(response.text)\n",
    "        return json_response\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "## Posting to the search bar of investing\n",
    "def _post_json_(url:str, headers={}, data={}):\n",
    "    print(\"Fetching {}..\".format(url))\n",
    "    response = requests.post(\n",
    "        url=url, \n",
    "        headers=headers,\n",
    "        data=data\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        json_response = json.loads(response.text)\n",
    "        return json_response\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function defined to extract the historical data of instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from user_agents import USER_AGENTS\n",
    "\n",
    "SEARCH_BAR_URL = \"https://www.investing.com/search/service/SearchInnerPage\"\n",
    "HISTORICAL_DATA_BASE_URL = \"https://api.investing.com/api/financialdata/historical/{0}\"\n",
    "\n",
    "common_headers ={\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    \"Accept\": \"text/html\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"domain-id\": \"www\",\n",
    "    \"user-agent\": random.choice(USER_AGENTS),\n",
    "    # \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "## Function to extract the table of OHLC\n",
    "def get_historical_data(args_tuple):\n",
    "    symbol, from_date, to_date = args_tuple[0].replace(\"/\",\"\"), args_tuple[1], args_tuple[2]\n",
    "    search_params = {\n",
    "        \"search_text\": symbol\n",
    "    }\n",
    "    try:\n",
    "        search_bar_data = _post_json_(\n",
    "            url=SEARCH_BAR_URL,\n",
    "            headers=common_headers,\n",
    "            data=search_params\n",
    "        )\n",
    "        result = search_bar_data[\"quotes\"]\n",
    "        if len(result) > 0:\n",
    "            investing_code = result[0][\"pairId\"]\n",
    "            category = result[0][\"link\"].split(\"/\")[1]\n",
    "            country = result[0][\"flag\"]\n",
    "            # print(investing_code, category, country)\n",
    "\n",
    "        ## for data scraping\n",
    "        output = []\n",
    "        historical_params = {\n",
    "            \"start-date\": from_date,\n",
    "            \"end-date\": to_date,\n",
    "            \"time-frame\": \"Daily\",\n",
    "            \"add-missing-rows\": \"False\"\n",
    "        }\n",
    "        response_data = _get_json_(\n",
    "            url=HISTORICAL_DATA_BASE_URL.format(investing_code),\n",
    "            headers=common_headers,\n",
    "            params=historical_params\n",
    "        )\n",
    "        historical_data = response_data[\"data\"]\n",
    "        for item in historical_data:\n",
    "            output.append({\n",
    "                \"Date\": item[\"rowDate\"],\n",
    "                \"Open\": item[\"last_open\"],\n",
    "                \"High\": item[\"last_max\"],\n",
    "                \"Low\": item[\"last_min\"],\n",
    "                \"Close\": item[\"last_close\"],\n",
    "                \"Volume\": item[\"volume\"],\n",
    "                \"Change\": item[\"change_precent\"]\n",
    "            })\n",
    "        # print(output)\n",
    "        current_dir = os.getcwd()\n",
    "        if os.path.exists(f\"{current_dir}/historical_data_csv\"):\n",
    "            path = current_dir + \"/\" + \"historical_data_csv\"\n",
    "            # print(path)\n",
    "        else:\n",
    "            os.mkdir(\"historical_data_csv\")\n",
    "            path = current_dir + \"/\" + \"historical_data_csv\"\n",
    "            # print(path)\n",
    "        field_names = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Change\"]\n",
    "        with open(\"{0}/{1}-{2}-{3}.csv\".format(path,symbol,category,country), \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile,fieldnames=field_names)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(output)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"{0} not found on investing website\".format(symbol))\n",
    "        return False\n",
    "        # return symbol\n",
    "\n",
    "# print(get_historical_data((\"LART\",\"2022-08-01\",\"2022-08-31\")))\n",
    "# print(get_historical_data((\"N225INV2\",\"2022-08-01\",\"2022-08-31\")))\n",
    "# print(get_historical_data((\"KTPU\",\"2022-08-01\",\"2022-08-31\"))) \n",
    "# print(get_historical_data((\"NIFTYAUTO\",\"2022-08-01\",\"2022-08-31\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function to link the `investing_code` with the searched symbol and saving the output to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def main():\n",
    "    symbols = input(\"Enter symbols(separated by , ): \").split(\",\")\n",
    "    from_date = input(\"Enter from date(yyyy-mm-dd): \")\n",
    "    to_date = input(\"Enter to date(yyyy-mm-dd): \")\n",
    "    if datetime.strptime(from_date,\"%Y-%m-%d\").date() > datetime.strptime(to_date,\"%Y-%m-%d\").date():\n",
    "        print(\"Your from_date is greater than the to_date\")\n",
    "    else:\n",
    "        historical_data_args = []\n",
    "        [historical_data_args.append((symbol,from_date,to_date)) for symbol in symbols]\n",
    "        ############ THREADING TECHNIQUE (500 Threads) #################\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            executor.map(get_historical_data,historical_data_args)\n",
    "\n",
    "        # print(historical_data_args[end-1])\n",
    "\n",
    "\n",
    "        ############  LOOPING TECHNIQUE ####################\n",
    "        \n",
    "        # for symbol in symbols:\n",
    "        #     historical_data_args.append((symbol,from_date,to_date))\n",
    "        # not_found_symbols = []\n",
    "        # for argument in historical_data_args:\n",
    "        #     result = get_historical_data(argument)\n",
    "        #     if result == True:\n",
    "        #         pass\n",
    "        #     else:\n",
    "        #         not_found_symbols.append(result)\n",
    "        # print(\"Not found symbols: \", not_found_symbols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution or calling of main function\n",
    "#### NOTE: Inputs to be splitted by a \",\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "# Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\n",
    "\n",
    "## TESTING STOCKS - Symbol Column\n",
    "# TS,APBR,GGAL,TXAR,PAMP,TECO2,BPAT,ALUA,BBAR,BMA,EDN,TRAN,MIRG,BHIP,AGRO,AUSO,,GAMI,EMBR3,ENBR3,ZGPS,\n",
    "# CPLE6,CRDE3,CSAN3,CSMG3,CSNA3,LIQO3,CTNM4,CYRE3,DASA3,DIRR3,DTEX3,ECOR3,EEEL3,ELEK4,ELET3,ELET6,PROJ,5EO,\n",
    "# CTSA3,CTSA4,CVCB3T,DOHL4,DTCY3,EALT4,EKTR4,ELEK3,EMAE4,ENGI3,ENMT3,ESTR4,FESA3,FNAM11,FSRF11KRIP,5CP,5SR,\n",
    "# PBJT,PLRP,PRPF,STVK,VBIP,VKNK,BRSP,CTRT,EDPL,EFNF,FRTF,NPRF,PVNF,UNFT,BOAT,ENPS,GINX,INGM,NTRN,SMPJ,TBOR,UNPL,600758,\n",
    "# 600490,600055,600203,600346,600381,600385,600418,600556,600576,600604,600610,600629,600634,600671,600682,600685,600730,\n",
    "# AURA,AVER,BBYL,FNTS,BLRX,ELWS,BRAN,BRIL,BWAY,BRMG,CAMT,CAST,CDEV,CANF,CGEN,CMER,DANE,DELT,DIFI,DIMRI,OPCT,600753\n",
    "\n",
    "### TESTING FUNDS - SYMBOL column\n",
    "# 0P0000YO4P,LP65153969,0P00012AYY,0P0000NGP0,0P00007IV4,0P0000Q7CG,0P0000O85Q,LP68040230,0P0000Q7CM,0P0000O85S,0P000077YZ,LP68077432,\n",
    "# 0P00014O2D,0P0000SJE0,0P000078OP,0P00007FN6,LP65014940,LP63512373,519931,0P0000KOZZ,519015,217001,0P0000G0N4,0P0000V9U3,\n",
    "# 0P0000JS6H,0P0000MXR7,240002,80002,450001,0P00009RFL,0P0000SU43,0P0000WN3S,0P0000WN3V,0P0000WN3U,0P00000CAX,0P00000RJZ,0P0000N6L3\n",
    "\n",
    "### TESTING ETF'S - SYMBOL column \n",
    "# QOZ,FEMX,USD,VGS,A200,F100,ETHI,VGAD,FLOT,QUAL,HVST,ASIA,VEU,WDMF,FTGG,FTGE,3USLG,7GX4,KUW8G,W311,KUW8G,W311,KUW8G,W311,1HSA,H4ZF\n",
    "\n",
    "### testing Indices - symbol column \n",
    "# AXINJD,AXMAJD,AXMEJD,AXAF,AXPBJD,AXAT,AXKO,AXJO,AXGD,AXDJ,AXSJ,AXEJ,AXFJ,AXHJ,AXNJ,AXIJ,AXMJ,AXPJ,AXJR,AXTJ,AXUJ,AXMM,AORD,\n",
    "# BSEMET,BSEOIL,BSEPOWER,BSEPSU,BSEREAL,NIFVIX,B50INCDN,NIFTY200,NSED,NV20,NIFTY500,NIFMDCP100,NIMDCP50,NN50,SPBSEFMCG,NIFSMCP100,NIFTY100\n",
    "\n",
    "## TESTING BONDS - name column \n",
    "# India 10YI,ndia 30Y,India 24Y,India 19Y,India 15Y,India 14Y,India 13Y,India 12Y,India 11Y,India 9Y,India 4Y\n",
    "\n",
    "### TESTING CERTIFICATES - symbol column\n",
    "# DEHY1Y7L,DEVZ716B,DECE8NK7,DECE6M8S,DEAA0XYR,DEAA0C4K,DE768918,DEABN0EW,DEAA0KFZ,DE918607,DEABN1EJ,DEDB3WT1,DEDZ0B77,DEDB3CTQ,DEDZ0B66,DEDZ2X4Q,DE635186\n",
    "\n",
    "### TESTING CRYPTOS - symbol column \n",
    "# BTC,ETH,BNB,USDT,ADA,DOT,XRP,UNI,LTC,LINK,THETA,USDC,BCH,XLM,LUNA\n",
    "\n",
    "### TESTING COMMODITIES - name column \n",
    "# MCX Aluminum Mini,MCX Aluminum,MCX Copper,MCX Copper Mini,MCX Gold 1 Kg,MCX Gold Guinea,MCX Gold Mini,MCX Gold Petal,MCX Gold Petal Del,MCX Lead,MCX Lead Mini,MCX Nickel\n",
    "\n",
    "### TESTING Forex - name column\n",
    "# USD/INR,USD/EUR,USD/JPY,INR/EUR,INR/JPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: If any of the time scraper stop to get the data. Interchange or uncomment the `user-agent` key of the `common_header`. Keep on changing, whenever it stops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24e825efde00d83ae8956899d00353005a5e8e868b3ba791ab8b91de6cfd1652"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
